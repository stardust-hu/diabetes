{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import norm, skew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw = pd.read_csv('../data/d_train.csv', index_col='id', encoding='gbk')\n",
    "test_raw = pd.read_csv('../data/d_test_A_20180102.csv', index_col='id', encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_columns = ['F{0}'.format(i+1) for i in range(train_raw.shape[1])]\n",
    "new_columns[-1] = 'blood_sugar'\n",
    "feature_map = pd.Series(index=new_columns, data=train_raw.columns)\n",
    "train_raw.columns = new_columns\n",
    "test_raw.columns = new_columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train_raw.iloc[:, :-1], test_raw], axis=0, join='outer').reset_index(drop=True)\n",
    "# 2是缺失值\n",
    "sex_dict = {u'男':'male', u'女':'female'}\n",
    "all_data.F1 = all_data.F1.apply(lambda x: sex_dict[x] if x in sex_dict.keys() else 'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train = train_raw.shape[0]\n",
    "n_test = test_raw.shape[0]\n",
    "\n",
    "train_raw.blood_sugar = np.log1p(train_raw.blood_sugar)\n",
    "y_train = train_raw.blood_sugar.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
    "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\n",
    "missing_data = pd.DataFrame({'Missing_Ratio' :all_data_na})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# F3: 日期\n",
    "drop_feature_list = ['F3', 'F19', 'F20', 'F21', 'F22', 'F23']\n",
    "all_data = all_data.drop(drop_feature_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data.iloc[:, 1:] = all_data.iloc[:, 1:].apply(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the skew of all numerical features\n",
    "skewed_feats = all_data.iloc[:, 1:].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "skewness = pd.DataFrame({'Skew' :skewed_feats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 33 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "skewness = skewness[abs(skewness) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    all_data[feat] = boxcox1p(all_data[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = all_data[:n_train]\n",
    "test = all_data[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, BayesianRidge, LassoLarsIC, Ridge, LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=0).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, train.values, y_train, scoring='neg_mean_squared_error', cv=kf))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = make_pipeline(RobustScaler(), Ridge(alpha=2.08, random_state=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=0.5, random_state=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GBoost = GradientBoostingRegressor(n_estimators=500, \n",
    "                                   learning_rate=0.05,\n",
    "                                   max_depth=4, \n",
    "                                   max_features='sqrt',\n",
    "                                   min_samples_leaf=15, \n",
    "                                   min_samples_split=10, \n",
    "                                   loss='huber', \n",
    "                                   random_state =3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, \n",
    "                             gamma=0.0468, \n",
    "                             learning_rate=0.05, \n",
    "                             max_depth=3, \n",
    "                             min_child_weight=1.7817, \n",
    "                             n_estimators=2200,\n",
    "                             reg_alpha=0.4640, \n",
    "                             reg_lambda=0.8571,\n",
    "                             subsample=0.5213, \n",
    "                             silent=1,\n",
    "                             seed=4, \n",
    "                             nthread = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lgb = lgb.LGBMRegressor(objective='regression',\n",
    "                              num_leaves=5,\n",
    "                              learning_rate=0.05, \n",
    "                              n_estimators=720,\n",
    "                              max_bin = 55, \n",
    "                              bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, \n",
    "                              feature_fraction = 0.2319,\n",
    "                              feature_fraction_seed=9, \n",
    "                              bagging_seed=9,\n",
    "                              min_data_in_leaf =6, \n",
    "                              min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge score: 0.1546 (0.0091)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ridge)\n",
    "print(\"\\nRidge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet score: 0.1546 (0.0091)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel Ridge score: 0.1523 (0.0093)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting score: 0.0499 (0.0029)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xgboost score: 0.1562 (0.0098)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM score: 0.1532 (0.0094)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 0.0492 (0.0028)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, KRR, ridge))\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=5):\n",
    "        self.base_models =base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        \n",
    "        kfold = KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
    "        \n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, hold_out_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[hold_out_index])\n",
    "                out_of_fold_predictions[hold_out_index, i] = y_pred\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([\n",
    "                model.predict(X) \n",
    "                for model in base_models]).mean(axis=1)\n",
    "                    for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1511 (0.0094)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (model_xgb, model_lgb, ENet, GBoost, KRR),\n",
    "                                                 meta_model = ridge)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 0.1511 (0.0094)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (model_xgb, model_lgb, ENet, GBoost, KRR),\n",
    "                                                 meta_model = ridge)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "#     y_pred = map(lambda x: float('%0.3f' % x), y_pred)\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.131713596106\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models.fit(train.values, y_train)\n",
    "stacked_train_pred = stacked_averaged_models.predict(train.values)\n",
    "stacked_pred = np.expm1(stacked_averaged_models.predict(test.values))\n",
    "print(rmsle(y_train, stacked_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0933179568238\n"
     ]
    }
   ],
   "source": [
    "model_xgb.fit(train, y_train)\n",
    "xgb_train_pred = model_xgb.predict(train)\n",
    "xgb_pred = np.expm1(model_xgb.predict(test))\n",
    "print(rmsle(y_train, xgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.123489867926\n"
     ]
    }
   ],
   "source": [
    "model_lgb.fit(train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(train)\n",
    "lgb_pred = np.expm1(model_lgb.predict(test.values))\n",
    "print(rmsle(y_train, lgb_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on train data:\n",
      "0.123476369234\n"
     ]
    }
   ],
   "source": [
    "print('RMSLE score on train data:')\n",
    "print(rmsle(y_train,stacked_train_pred*0.70 +\n",
    "            xgb_train_pred*0.15 + \n",
    "            lgb_train_pred*0.15 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble = stacked_pred*0.70 + xgb_pred*0.15 + lgb_pred*0.15\n",
    "ensemble = stacked_pred\n",
    "ensemble = map(lambda x: '%0.3f' % x, ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['blood_sugar'] = ensemble\n",
    "sub.to_csv('../data/submission.csv',index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:xgboost]",
   "language": "python",
   "name": "conda-env-xgboost-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
